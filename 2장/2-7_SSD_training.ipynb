{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"mount_file_id":"1sFdNgfhymvQN6EUm1KJ6rixGZrswULZq","authorship_tag":"ABX9TyPVwhpGL1va1BKn/4k+UY2Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#학습과 검증을 실시"],"metadata":{"id":"MhvhJ2Btq6Xd"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"ywsmrqsaZPx5","executionInfo":{"status":"ok","timestamp":1664646595643,"user_tz":-540,"elapsed":4232,"user":{"displayName":"서대원","userId":"14861959776549124094"}}},"outputs":[],"source":["import os.path as osp\n","import random\n","import time\n","\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.init as init\n","import torch.optim as optim\n","import torch.utils.data as data"]},{"cell_type":"markdown","source":["#utils를 포함한 필요한 패키지를 import"],"metadata":{"id":"TLDv6UGeq5Wf"}},{"cell_type":"code","source":["torch.manual_seed(1234)\n","np.random.seed(1234)\n","random.seed(1234)"],"metadata":{"id":"ghmVPn4Ffk3I","executionInfo":{"status":"ok","timestamp":1664646595643,"user_tz":-540,"elapsed":5,"user":{"displayName":"서대원","userId":"14861959776549124094"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"사용장치：\", device)"],"metadata":{"id":"xW8rzxLRflht","executionInfo":{"status":"ok","timestamp":1664646595644,"user_tz":-540,"elapsed":5,"user":{"displayName":"서대원","userId":"14861959776549124094"}},"outputId":"0b94b091-4d9f-4f82-a0db-e39037d41d92","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["사용장치： cuda:0\n"]}]},{"cell_type":"markdown","source":["#사용중인 장치는 GPU"],"metadata":{"id":"zBZP7sdyrQgd"}},{"cell_type":"code","source":["from utils.ssd_model import make_datapath_list, VOCDataset, DataTransform, Anno_xml2list, od_collate_fn\n","\n","\n","rootpath = \"./drive/MyDrive/Colab Notebooks/2_objectdetection/data/VOCdevkit/VOC2012/\"\n","train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(\n","    rootpath)\n","\n","voc_classes = ['aeroplane', 'bicycle', 'bird', 'boat',\n","               'bottle', 'bus', 'car', 'cat', 'chair',\n","               'cow', 'diningtable', 'dog', 'horse',\n","               'motorbike', 'person', 'pottedplant',\n","               'sheep', 'sofa', 'train', 'tvmonitor']\n","color_mean = (104, 117, 123)\n","input_size = 300\n","\n","train_dataset = VOCDataset(train_img_list, train_anno_list, phase=\"train\", transform=DataTransform(\n","    input_size, color_mean), transform_anno=Anno_xml2list(voc_classes))\n","\n","val_dataset = VOCDataset(val_img_list, val_anno_list, phase=\"val\", transform=DataTransform(\n","    input_size, color_mean), transform_anno=Anno_xml2list(voc_classes))\n","\n","\n","batch_size = 32\n","\n","train_dataloader = data.DataLoader(\n","    train_dataset, batch_size=batch_size, shuffle=True, collate_fn=od_collate_fn)\n","\n","val_dataloader = data.DataLoader(\n","    val_dataset, batch_size=batch_size, shuffle=False, collate_fn=od_collate_fn)\n","\n","dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}"],"metadata":{"id":"xL_g71xjflwj","executionInfo":{"status":"ok","timestamp":1664646602115,"user_tz":-540,"elapsed":6474,"user":{"displayName":"서대원","userId":"14861959776549124094"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["#SSD를 학습시킬 데이터 셋과 데이터 로더를 앞에서 구현한 파일들과 같이 작성"],"metadata":{"id":"ThJF2ajorKB0"}},{"cell_type":"code","source":["from utils.ssd_model import SSD\n","\n","ssd_cfg = {\n","    'num_classes': 21,\n","    'input_size': 300,\n","    'bbox_aspect_num': [4, 6, 6, 6, 4, 4],\n","    'feature_maps': [38, 19, 10, 5, 3, 1],\n","    'steps': [8, 16, 32, 64, 100, 300],\n","    'min_sizes': [30, 60, 111, 162, 213, 264],\n","    'max_sizes': [60, 111, 162, 213, 264, 315],\n","    'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n","}\n","\n","net = SSD(phase=\"train\", cfg=ssd_cfg)\n","\n","vgg_weights = torch.load(\"./drive/MyDrive/Colab Notebooks/2_objectdetection/weights/vgg16_reducedfc.pth\")\n","net.vgg.load_state_dict(vgg_weights)\n","\n","\n","\n","def weights_init(m):\n","    if isinstance(m, nn.Conv2d):\n","        init.kaiming_normal_(m.weight.data)\n","        if m.bias is not None:\n","            nn.init.constant_(m.bias, 0.0)\n","\n","\n","net.extras.apply(weights_init)\n","net.loc.apply(weights_init)\n","net.conf.apply(weights_init)\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"사용 중인 장치：\", device)\n","\n","print('네트워크 설정 완료: 학습된 가중치를 로드했습니다.')"],"metadata":{"id":"XQQt5NE0fm9K","executionInfo":{"status":"ok","timestamp":1664646604624,"user_tz":-540,"elapsed":2520,"user":{"displayName":"서대원","userId":"14861959776549124094"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8a017881-413d-48af-c584-c889fecfcbbf"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["사용 중인 장치： cuda:0\n","네트워크 설정 완료: 학습된 가중치를 로드했습니다.\n"]}]},{"cell_type":"markdown","source":["#SSD의 설정은 전장과 똑같이 설정 후 GPU를 사용할 수 있는지 확인"],"metadata":{"id":"EzTaZPIJrrCc"}},{"cell_type":"code","source":["from utils.ssd_model import MultiBoxLoss\n","\n","criterion = MultiBoxLoss(jaccard_thresh=0.5, neg_pos=3, device=device)\n","\n","optimizer = optim.SGD(net.parameters(), lr=1e-3,\n","                      momentum=0.9, weight_decay=5e-4)"],"metadata":{"id":"xbfyJSmOfqGV","executionInfo":{"status":"ok","timestamp":1664646604625,"user_tz":-540,"elapsed":13,"user":{"displayName":"서대원","userId":"14861959776549124094"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["#손실함수와 최적화 기법을 설정"],"metadata":{"id":"mVT6R4ngr2uy"}},{"cell_type":"code","source":["def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n","\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    print(\"사용 중인 장치:\", device)\n","\n","    net.to(device)\n","\n","    torch.backends.cudnn.benchmark = True\n","\n","    iteration = 1\n","    epoch_train_loss = 0.0\n","    epoch_val_loss = 0.0\n","    logs = []\n","\n","    for epoch in range(num_epochs+1):\n","\n","        t_epoch_start = time.time()\n","        t_iter_start = time.time()\n","\n","        print('-------------')\n","        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n","        print('-------------')\n","\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                net.train()\n","                print('（train）')\n","            else:\n","                if((epoch+1) % 10 == 0):\n","                    net.eval()\n","                    print('-------------')\n","                    print('（val）')\n","                else:\n","                    continue\n","\n","\n","            for images, targets in dataloaders_dict[phase]:\n","\n","                images = images.to(device)\n","                targets = [ann.to(device)\n","                           for ann in targets]\n","\n","                optimizer.zero_grad()\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = net(images)\n","\n","                    loss_l, loss_c = criterion(outputs, targets)\n","                    loss = loss_l + loss_c\n","\n","                    if phase == 'train':\n","                        loss.backward()\n","\n","                        nn.utils.clip_grad_value_(\n","                            net.parameters(), clip_value=2.0)\n","\n","                        optimizer.step()\n","\n","                        if (iteration % 10 == 0):\n","                            t_iter_finish = time.time()\n","                            duration = t_iter_finish - t_iter_start\n","                            print('반복 {} || Loss: {:.4f} || 10iter: {:.4f} sec.'.format(\n","                                iteration, loss.item(), duration))\n","                            t_iter_start = time.time()\n","\n","                        epoch_train_loss += loss.item()\n","                        iteration += 1\n","\n","                    else:\n","                        epoch_val_loss += loss.item()\n","\n","        t_epoch_finish = time.time()\n","        print('-------------')\n","        print('epoch {} || Epoch_TRAIN_Loss:{:.4f} ||Epoch_VAL_Loss:{:.4f}'.format(\n","            epoch+1, epoch_train_loss, epoch_val_loss))\n","        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n","        t_epoch_start = time.time()\n","\n","        log_epoch = {'epoch': epoch+1,\n","                     'train_loss': epoch_train_loss, 'val_loss': epoch_val_loss}\n","        logs.append(log_epoch)\n","        df = pd.DataFrame(logs)\n","        df.to_csv(\"log_output.csv\")\n","\n","        epoch_train_loss = 0.0\n","        epoch_val_loss = 0.0\n","\n","        if ((epoch+1) % 10 == 0):\n","            torch.save(net.state_dict(), 'weights/ssd300_' +\n","                       str(epoch+1) + '.pth')"],"metadata":{"id":"vJZHMs1amGVk","executionInfo":{"status":"ok","timestamp":1664646604625,"user_tz":-540,"elapsed":13,"user":{"displayName":"서대원","userId":"14861959776549124094"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["#모델을 학습시키는 함수를 작성"],"metadata":{"id":"evxe3jZzr85e"}},{"cell_type":"code","source":["num_epochs= 2  \n","train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"],"metadata":{"id":"bE1xob-kfriC","executionInfo":{"status":"error","timestamp":1664650159929,"user_tz":-540,"elapsed":3555317,"user":{"displayName":"서대원","userId":"14861959776549124094"}},"colab":{"base_uri":"https://localhost:8080/","height":604},"outputId":"4453199e-dcf1-412d-cf68-0c69d6b882f9"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["사용 중인 장치: cuda:0\n","-------------\n","Epoch 1/2\n","-------------\n","（train）\n"]},{"output_type":"stream","name":"stderr","text":["/content/utils/data_augumentation.py:246: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  mode = random.choice(self.sample_options)\n"]},{"output_type":"stream","name":"stdout","text":["반복 10 || Loss: 16.5938 || 10iter: 725.1825 sec.\n","반복 20 || Loss: 12.8930 || 10iter: 497.1597 sec.\n","반복 30 || Loss: 9.8050 || 10iter: 477.9840 sec.\n","반복 40 || Loss: 9.0011 || 10iter: 493.2138 sec.\n","반복 50 || Loss: 8.2550 || 10iter: 501.9406 sec.\n","반복 60 || Loss: 8.2358 || 10iter: 485.1716 sec.\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-f2332df40959>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-7-68ec388c0440>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(net, dataloaders_dict, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/utils/ssd_model.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0m전처리한\u001b[0m \u001b[0m화상의\u001b[0m \u001b[0m텐서\u001b[0m \u001b[0m형식\u001b[0m \u001b[0m데이터와\u001b[0m \u001b[0m어노테이션을\u001b[0m \u001b[0m취득\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         '''\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpull_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/utils/ssd_model.py\u001b[0m in \u001b[0;36mpull_item\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;31m# 1. 화상 읽기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mimage_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_file_path\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [높이][폭][색BGR]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m         \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m  \u001b[0;31m# 화상의 크기 취득\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["#학습 및 검증을 실행"],"metadata":{"id":"FspZelgFsGAp"}}]}